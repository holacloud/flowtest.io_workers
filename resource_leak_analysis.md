# An√°lisis de Posibles Resource Leaks

## Resumen Ejecutivo 

He analizado el c√≥digo de `flowtest_workers` y encontr√© **varios resource leaks confirmados y potenciales** que deben ser corregidos.

---

## üî¥ Problemas Cr√≠ticos Encontrados

### 1. **Goroutine Leak en [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go) - [dispatch()](file:///home/user/flowtest_workers/worker/manager.go#484-494)**
**Archivo:** [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L269-L295)  
**Severidad:** üî¥ CR√çTICA

#### Problema:
```go
func (m *Manager) dispatch(ctx context.Context, workerID string, request *ProxyRequest) (*ProxyResponse, error) {
    // ...
    job := &job{
        request:   request,
        responseC: make(chan *ProxyResponse, 1),  // Canal creado
    }

    select {
    case worker.jobs <- job:
    case <-ctx.Done():
        return nil, ErrRequestCancelled  // ‚ö†Ô∏è Canal nunca cerrado
    }

    select {
    case <-ctx.Done():
        worker.unregisterPending(request.ID)
        return nil, ErrRequestCancelled  // ‚ö†Ô∏è Canal nunca cerrado
    case resp := <-job.responseC:
        return resp, nil
    }
}
```

#### ¬øPor qu√© es un leak?
El canal `job.responseC` se crea pero **nunca se cierra**. Si el contexto se cancela antes de que el worker responda, el canal queda hu√©rfano en memoria y no ser√° recolectado por el GC.

#### Impacto:
- **Memory leak:** Cada request cancelado deja un canal de 1 buffer en memoria
- **Acumulaci√≥n progresiva:** En sistemas con alta carga y timeouts frecuentes, puede consumir memoria significativa

#### Soluci√≥n Recomendada:
```go
func (m *Manager) dispatch(ctx context.Context, workerID string, request *ProxyRequest) (*ProxyResponse, error) {
    // ...
    job := &job{
        request:   request,
        responseC: make(chan *ProxyResponse, 1),
    }
    defer close(job.responseC)  // ‚úÖ Cerrar canal al salir

    // resto del c√≥digo...
}
```

---

### 2. **Channel Leak en [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go) - Worker.jobs**
**Archivo:** [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L110)  
**Severidad:** üî¥ CR√çTICA

#### Problema:
```go
func (m *Manager) Register(suiteID, name string) *Worker {
    worker := &Worker{
        // ...
        jobs: make(chan *job, 32),  // Canal creado
        // ...
    }
    // ...
    return worker
}
```

El canal `worker.jobs` se crea cuando se registra un worker pero **nunca se cierra** cuando el worker se elimina.

#### C√≥digo de eliminaci√≥n:
```go
func (m *Manager) removeWorkerLocked(workerID string) {
    worker, ok := m.workers[workerID]
    if !ok {
        return
    }

    delete(m.workers, workerID)  // ‚ö†Ô∏è Worker eliminado pero canal no cerrado
    // ... resto del c√≥digo de limpieza ...
}
```

#### Impacto:
- **Channel leak:** Cada worker eliminado deja un canal abierto con buffer de 32
- **Goroutine leak potencial:** Si hay goroutines leyendo/escribiendo en ese canal
- **Memory leak:** Los jobs pendientes en el canal no ser√°n liberados

#### Soluci√≥n Recomendada:
```go
func (m *Manager) removeWorkerLocked(workerID string) {
    worker, ok := m.workers[workerID]
    if !ok {
        return
    }

    // ‚úÖ Cerrar canal antes de eliminar
    close(worker.jobs)

    delete(m.workers, workerID)
    
    // resto del c√≥digo...
}
```

**Advertencia:** Cerrar el canal puede causar panic si hay goroutines intentando escribir. Necesitas agregar recover o verificar que no haya escritores activos.

---

### 3. **HTTP Response Body No Cerrado en [main.go](file:///home/user/flowtest_workers/main.go) - [registerWorker()](file:///home/user/flowtest_workers/main.go#98-161)**
**Archivo:** [main.go](file:///home/user/flowtest_workers/main.go#L115-L128)  
**Severidad:** üü° MEDIA-ALTA

#### Problema:
```go
func registerWorker(ctx context.Context, client *http.Client, ...) (string, error) {
    // ...
    for {
        // ...
        resp, err := client.Do(req)
        if err != nil {
            if ctx.Err() != nil {
                return "", ctx.Err()  // ‚ö†Ô∏è resp puede estar nil, pero si no lo est√°...
            }
            log.Printf("register worker: %v; retrying in 5s", err)
            if !sleepWithContext(ctx, 5*time.Second) {
                return "", ctx.Err()  // ‚ö†Ô∏è Salida sin verificar resp
            }
            continue
        }

        data, _ := io.ReadAll(resp.Body)
        resp.Body.Close()  // ‚úÖ Cerrado aqu√≠, pero solo si no hay error
        // ...
    }
}
```

#### ¬øCu√°l es el problema?
Si `client.Do(req)` retorna un error **y** un `resp` no-nil (v√°lido en Go cuando hay errores de redirect u otros escenarios), el `resp.Body` **no se cierra** en los casos de continue/return dentro del `if err != nil`.

#### Documentaci√≥n de Go:
> On error, any Response can be ignored. A non-nil Response with a non-nil error only occurs when CheckRedirect fails, and even then the returned Response.Body is already closed.

En este caso espec√≠fico, el `CheckRedirect` est√° configurado en l√≠nea 51 de [main.go](file:///home/user/flowtest_workers/main.go#L51), pero solo para `targetClient`, no para `serverClient` (l√≠nea 48).

#### Impacto:
- **Connection leak:** Conexiones TCP/TLS no liberadas
- **File descriptor leak:** En sistemas con muchas conexiones, puede agotar descriptores
- **Nivel de riesgo:** BAJO en la pr√°ctica porque el error t√≠picamente viene con Body cerrado, pero es una mala pr√°ctica

#### Soluci√≥n Recomendada:
```go
resp, err := client.Do(req)
if resp != nil {
    defer resp.Body.Close()  // ‚úÖ Siempre cerrar si resp != nil
}
if err != nil {
    // manejar error...
}
```

---

### 4. **Mismo Problema en [pullRequest()](file:///home/user/flowtest_workers/main.go#173-200), [submitResponse()](file:///home/user/flowtest_workers/main.go#242-263)**
**Archivos:** 
- [main.go](file:///home/user/flowtest_workers/main.go#L173-L199) - [pullRequest()](file:///home/user/flowtest_workers/main.go#173-200)
- [main.go](file:///home/user/flowtest_workers/main.go#L242-L262) - [submitResponse()](file:///home/user/flowtest_workers/main.go#242-263)

**Severidad:** üü° MEDIA

#### Problema:
Aunque estas funciones tienen `defer resp.Body.Close()`, lo hacen **despu√©s** de verificar el error:

```go
func pullRequest(ctx context.Context, client *http.Client, server, workerID string) (*ProxyRequest, error) {
    // ...
    resp, err := client.Do(req)
    if err != nil {
        return nil, err  // ‚ö†Ô∏è Si resp != nil, no se cierra
    }
    defer resp.Body.Close()  // Solo se ejecuta si err == nil
    // ...
}
```

#### Soluci√≥n:
Mismo patr√≥n que arriba - mover el `defer` antes del check de error.

---

### 5. **HTTP Request Body No Cerrado en [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go) - `proxyTransport.RoundTrip()`**
**Archivo:** [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L438-L481)  
**Severidad:** üü¢ BAJA (pero es mala pr√°ctica)

#### Problema:
```go
func (t *proxyTransport) RoundTrip(req *http.Request) (*http.Response, error) {
    body := []byte{}
    if req.Body != nil {
        data, err := io.ReadAll(req.Body)  // ‚ö†Ô∏è Lee pero no cierra
        if err != nil {
            return nil, err
        }
        body = data
    }
    // ...
}
```

#### ¬øPor qu√© es un problema?
Seg√∫n la documentaci√≥n de `http.RoundTripper`:
> RoundTrip should not modify the request, except for consuming and closing the Request's Body.

El c√≥digo **consume** el body pero **no lo cierra**.

#### Impacto:
- **Nivel bajo:** El caller t√≠picamente cierra el body, pero es responsabilidad del RoundTripper
- **Puede causar warnings/errores** en pruebas o con ciertos HTTP clients

#### Soluci√≥n:
```go
if req.Body != nil {
    defer req.Body.Close()  // ‚úÖ Cerrar seg√∫n especificaci√≥n
    data, err := io.ReadAll(req.Body)
    if err != nil {
        return nil, err
    }
    body = data
}
```

---

## üü° Problemas Potenciales de Memoria

### 6. **Map Growth Sin L√≠mites en [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go)**
**Archivo:** [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L26-L29)  
**Severidad:** üü° MEDIA

#### Problema:
```go
type Manager struct {
    mu      sync.RWMutex
    workers map[string]*Worker      // ‚ö†Ô∏è Puede crecer indefinidamente
    bySuite map[string]map[string]*workerPool  // ‚ö†Ô∏è Mapa anidado sin l√≠mite
}
```

#### ¬øPor qu√© es un problema?
- Los workers "stale" se eliminan en [pruneLocked()](file:///home/user/flowtest_workers/worker/manager.go#382-389) pero **solo cuando se llama expl√≠citamente**
- El pruning se hace en [List()](file:///home/user/flowtest_workers/worker/manager.go#133-157), [hasWorker()](file:///home/user/flowtest_workers/worker/manager.go#324-339), y [nextWorker()](file:///home/user/flowtest_workers/worker/manager.go#340-381), pero **no en un background goroutine**
- Si nadie llama estas funciones, workers viejos **nunca se eliminan**

#### Escenario de leak:
1. Worker se registra
2. Worker se desconecta/muere
3. Nadie llama [List()](file:///home/user/flowtest_workers/worker/manager.go#133-157) o [nextWorker()](file:///home/user/flowtest_workers/worker/manager.go#340-381)
4. Worker permanece en memoria indefinidamente

#### Soluci√≥n Recomendada:
Agregar goroutine de limpieza peri√≥dica:
```go
func NewManager() *Manager {
    m := &Manager{
        workers: map[string]*Worker{},
        bySuite: map[string]map[string]*workerPool{},
    }
    
    // ‚úÖ Goroutine de limpieza peri√≥dica
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        for range ticker.C {
            m.mu.Lock()
            m.pruneLocked(time.Now())
            m.mu.Unlock()
        }
    }()
    
    return m
}
```

**Importante:** Esta goroutine tambi√©n es un leak si el Manager nunca se destruye, necesitas mecanismo de shutdown.

---

### 7. **Pending Jobs Sin Cleanup en Worker**
**Archivo:** [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L82)  
**Severidad:** üü° MEDIA

#### Problema:
```go
type Worker struct {
    // ...
    pending map[string]*job  // ‚ö†Ô∏è Jobs que nunca completan
}
```

Cuando un worker se elimina en [removeWorkerLocked()](file:///home/user/flowtest_workers/worker/manager.go#390-429), **no se limpian los pending jobs**:

```go
func (m *Manager) removeWorkerLocked(workerID string) {
    worker, ok := m.workers[workerID]
    if !ok {
        return
    }

    delete(m.workers, workerID)
    // ‚ö†Ô∏è worker.pending NO se limpia
    // ‚ö†Ô∏è Los goroutines esperando respuestas quedar√°n bloqueados
}
```

#### Impacto:
- **Memory leak:** Cada job tiene un [ProxyRequest](file:///home/user/flowtest_workers/worker/manager.go#52-60) y `responseC` que no se liberan
- **Goroutine leak:** Goroutines esperando en `job.responseC` nunca reciben respuesta

#### Soluci√≥n:
```go
func (m *Manager) removeWorkerLocked(workerID string) {
    worker, ok := m.workers[workerID]
    if !ok {
        return
    }

    // ‚úÖ Cancelar todos los pending jobs
    worker.mu.Lock()
    for _, job := range worker.pending {
        select {
        case job.responseC <- &ProxyResponse{
            RequestID: job.request.ID,
            Error:     "worker disconnected",
        }:
        default:
        }
    }
    worker.pending = nil
    worker.mu.Unlock()

    delete(m.workers, workerID)
    // ...
}
```

---

## üü¢ Buenas Pr√°cticas Observadas

### ‚úÖ Aspectos Positivos:

1. **Contextos manejados correctamente** en [main.go](file:///home/user/flowtest_workers/main.go#L45-L46)
   ```go
   ctx, cancel := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
   defer cancel()
   ```

2. **Timer correctamente limpiado** en [main.go](file:///home/user/flowtest_workers/main.go#L163-L164)
   ```go
   timer := time.NewTimer(delay)
   defer timer.Stop()
   ```

3. **Ticker limpiado** en [worker/manager.go](file:///home/user/flowtest_workers/worker/manager.go#L222-L223)
   ```go
   ticker := time.NewTicker(workerHeartbeatInterval)
   defer ticker.Stop()
   ```

4. **HTTP clients reutilizados** - No se crean nuevos clientes en cada request

---

## üìã Resumen de Prioridades

| # | Problema | Severidad | Impacto | Esfuerzo |
|---|----------|-----------|---------|----------|
| 1 | Channel leak en [dispatch()](file:///home/user/flowtest_workers/worker/manager.go#484-494) | üî¥ Alta | Alto - memory leak acumulativo | Bajo |
| 2 | Channel leak en [removeWorkerLocked()](file:///home/user/flowtest_workers/worker/manager.go#390-429) | üî¥ Alta | Alto - m√∫ltiples leaks | Medio |
| 7 | Pending jobs sin cleanup | üî¥ Alta | Goroutine + memory leak | Medio |
| 3-4 | HTTP Response Body no cerrado | üü° Media | Connection leaks | Bajo |
| 5 | HTTP Request Body no cerrado | üü° Media | Mala pr√°ctica | Bajo |
| 6 | Map growth sin l√≠mites | üü° Media | Memory leak gradual | Medio |

---

## üîß Recomendaciones de Implementaci√≥n

### Orden Sugerido:
1. **Primero:** Arreglar channel leaks (#1, #2) - Son los m√°s peligrosos
2. **Segundo:** Limpiar pending jobs (#7) - Evita goroutine leaks
3. **Tercero:** Agregar background pruning (#6) - Previene growth sin control
4. **Cuarto:** Arreglar HTTP body leaks (#3-5) - Completitud

### Testing Recomendado:
- **Pruebas de stress** con muchos workers registr√°ndose/desconect√°ndose
- **Pruebas de timeout** para verificar cleanup de requests cancelados
- **Memory profiling** con `pprof` para confirmar que no hay leaks
- **Goroutine profiling** para detectar goroutines hu√©rfanas

---

## üìö Referencias √ötiles

- [Effective Go - Defer, Panic, and Recover](https://golang.org/doc/effective_go#defer)
- [Go Blog - Concurrency Patterns](https://blog.golang.org/pipelines)
- [HTTP Client Best Practices](https://golang.org/pkg/net/http/#Client)
